{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-27T00:45:30.789440Z","iopub.status.busy":"2024-11-27T00:45:30.788912Z","iopub.status.idle":"2024-11-27T00:45:32.074310Z","shell.execute_reply":"2024-11-27T00:45:32.073006Z","shell.execute_reply.started":"2024-11-27T00:45:30.789385Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np  # linear algebra\n","import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","\n","for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T00:47:30.409857Z","iopub.status.busy":"2024-11-27T00:47:30.409281Z","iopub.status.idle":"2024-11-27T00:47:42.452923Z","shell.execute_reply":"2024-11-27T00:47:42.451727Z","shell.execute_reply.started":"2024-11-27T00:47:30.409818Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sentence-transformers\n","  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (4.46.3)\n","Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n","Requirement already satisfied: torch>=1.11.0 in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (2.4.1)\n","Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.2)\n","Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (0.26.2)\n","Requirement already satisfied: Pillow in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n","Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n","Requirement already satisfied: sympy in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n","Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (73.0.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.7.24)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n","Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n","Installing collected packages: sentence-transformers\n","Successfully installed sentence-transformers-3.3.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -U sentence-transformers"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T01:40:06.046253Z","iopub.status.busy":"2024-11-27T01:40:06.045326Z","iopub.status.idle":"2024-11-27T01:40:06.363554Z","shell.execute_reply":"2024-11-27T01:40:06.361932Z","shell.execute_reply.started":"2024-11-27T01:40:06.046176Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\n","    \"/Users/ramazanovaaa/Documents/Duke files/IDS703 NLP/Document_Similarity_with_BERT/dataset/synthetic/synthetic_data2.csv\"\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>doc1</th>\n","      <th>doc2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>It is a truth universally acknowledged, that a...</td>\n","      <td>It is a widely accepted fact that a wealthy si...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>However little known the feelings or views of ...</td>\n","      <td>No matter how little is known about a man's th...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>\"My dear Mr. Bennet,\" said his lady to him one...</td>\n","      <td>\"Mr. Bennet, my dear,\" his wife remarked one d...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Mr. Bennet replied that he had not.</td>\n","      <td>Mr. Bennet responded that he had not heard.</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>\"But it is,\" returned she; \"for Mrs. Long has ...</td>\n","      <td>\"But it is true,\" she replied. \"Mrs. Long was ...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>56</td>\n","      <td>56</td>\n","      <td>113</td>\n","      <td>114</td>\n","      <td>Mr. Bennet was so odd a mixture of quick parts...</td>\n","      <td>Mr. Bennet was such a peculiar blend of sharp ...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>57</td>\n","      <td>57</td>\n","      <td>115</td>\n","      <td>116</td>\n","      <td>_Her_ mind was less difficult to develope.</td>\n","      <td>Her personality was much easier to understand.</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>58</td>\n","      <td>58</td>\n","      <td>117</td>\n","      <td>118</td>\n","      <td>She was a woman of mean understanding, little ...</td>\n","      <td>She was a woman of limited intelligence, scant...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>59</td>\n","      <td>59</td>\n","      <td>119</td>\n","      <td>120</td>\n","      <td>When she was discontented she fancied herself ...</td>\n","      <td>When she felt unhappy, she imagined herself to...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>60</td>\n","      <td>60</td>\n","      <td>121</td>\n","      <td>122</td>\n","      <td>The business of her life was to get her daught...</td>\n","      <td>Her life’s mission was marrying off her daught...</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>61 rows × 7 columns</p>\n","</div>"],"text/plain":["    Unnamed: 0  id  qid1  qid2  \\\n","0            0   0     1     2   \n","1            1   1     3     4   \n","2            2   2     5     6   \n","3            3   3     7     8   \n","4            4   4     9    10   \n","..         ...  ..   ...   ...   \n","56          56  56   113   114   \n","57          57  57   115   116   \n","58          58  58   117   118   \n","59          59  59   119   120   \n","60          60  60   121   122   \n","\n","                                                 doc1  \\\n","0   It is a truth universally acknowledged, that a...   \n","1   However little known the feelings or views of ...   \n","2   \"My dear Mr. Bennet,\" said his lady to him one...   \n","3                 Mr. Bennet replied that he had not.   \n","4   \"But it is,\" returned she; \"for Mrs. Long has ...   \n","..                                                ...   \n","56  Mr. Bennet was so odd a mixture of quick parts...   \n","57         _Her_ mind was less difficult to develope.   \n","58  She was a woman of mean understanding, little ...   \n","59  When she was discontented she fancied herself ...   \n","60  The business of her life was to get her daught...   \n","\n","                                                 doc2  is_duplicate  \n","0   It is a widely accepted fact that a wealthy si...           NaN  \n","1   No matter how little is known about a man's th...           NaN  \n","2   \"Mr. Bennet, my dear,\" his wife remarked one d...           NaN  \n","3         Mr. Bennet responded that he had not heard.           NaN  \n","4   \"But it is true,\" she replied. \"Mrs. Long was ...           NaN  \n","..                                                ...           ...  \n","56  Mr. Bennet was such a peculiar blend of sharp ...           NaN  \n","57     Her personality was much easier to understand.           NaN  \n","58  She was a woman of limited intelligence, scant...           NaN  \n","59  When she felt unhappy, she imagined herself to...           NaN  \n","60  Her life’s mission was marrying off her daught...           NaN  \n","\n","[61 rows x 7 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["## Cosine Similarity using BERT embedding"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T01:23:46.773332Z","iopub.status.busy":"2024-11-27T01:23:46.772618Z","iopub.status.idle":"2024-11-27T01:23:46.779967Z","shell.execute_reply":"2024-11-27T01:23:46.778590Z","shell.execute_reply.started":"2024-11-27T01:23:46.773288Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModel\n","import torch\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T01:24:12.783613Z","iopub.status.busy":"2024-11-27T01:24:12.783145Z","iopub.status.idle":"2024-11-27T01:24:12.794785Z","shell.execute_reply":"2024-11-27T01:24:12.793420Z","shell.execute_reply.started":"2024-11-27T01:24:12.783574Z"},"trusted":true},"outputs":[],"source":["def compute_similarity(sentences, model_name=\"bert-base-uncased\", max_length=512):\n","    \"\"\"\n","    Compute the cosine similarity between the first sentence and all others using a pre-trained BERT model.\n","\n","    Args:\n","        sentences (list of list of str): A list of sentences where the first one is compared to the rest.\n","        model_name (str): The pre-trained BERT model name (default: 'bert-base-uncased').\n","        max_length (int): Maximum sequence length for tokenization (default: 128).\n","\n","    Returns:\n","        numpy.ndarray: Cosine similarity values between the first sentence and the rest.\n","    \"\"\"\n","    # Load tokenizer and model\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModel.from_pretrained(model_name)\n","\n","    # Tokenization and input preparation\n","    tokens = {\"input_ids\": [], \"attention_mask\": []}\n","    for sentence in sentences:\n","        new_tokens = tokenizer.encode_plus(\n","            \"\\n\".join(sentence),\n","            max_length=max_length,\n","            truncation=True,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\",\n","        )\n","        tokens[\"input_ids\"].append(new_tokens[\"input_ids\"][0])\n","        tokens[\"attention_mask\"].append(new_tokens[\"attention_mask\"][0])\n","\n","    tokens[\"input_ids\"] = torch.stack(tokens[\"input_ids\"])\n","    tokens[\"attention_mask\"] = torch.stack(tokens[\"attention_mask\"])\n","\n","    # Generate embeddings\n","    outputs = model(**tokens)\n","    embeddings = outputs.last_hidden_state\n","    attention = tokens[\"attention_mask\"]\n","\n","    # Mask embeddings\n","    mask = attention.unsqueeze(-1).expand(embeddings.shape).float()\n","    masked_embeddings = embeddings * mask\n","\n","    # Compute mean pooling\n","    summed = torch.sum(masked_embeddings, dim=1)\n","    counts = torch.clamp(mask.sum(dim=1), min=1e-9)\n","    mean_pooled = summed / counts\n","    mean_pooled = mean_pooled.detach().numpy()\n","\n","    # Compute cosine similarity\n","    similarity = cosine_similarity([mean_pooled[0]], mean_pooled[1:])\n","    return similarity"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T01:25:01.560904Z","iopub.status.busy":"2024-11-27T01:25:01.560480Z","iopub.status.idle":"2024-11-27T01:25:05.033890Z","shell.execute_reply":"2024-11-27T01:25:05.032600Z","shell.execute_reply.started":"2024-11-27T01:25:01.560859Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([0.9951054], dtype=float32)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["compute_similarity([\"This is the test1\", \"This is the test2\"])[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Document Summarization approach with BERT & Cosine Similarity"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["res_l = [\n","    [\"Today is a very sunny day.\", \"It's such a bright and sunny day today.\"],\n","    [\n","        \"I am hungry, I will get my meal.\",\n","        \"I feel like eating something because I am hungry.\",\n","    ],\n","    [\n","        \"Can you help me with this project?\",\n","        \"I need assistance with this task. Can you help?\",\n","    ],\n","    [\n","        \"The movie was better than I expected.\",\n","        \"I didn’t think the movie would be good, but it surprised me.\",\n","    ],\n","    [\n","        \"The library is open until 8 PM.\",\n","        \"The weather is horrible, it's raining all day.\",\n","    ],\n","    [\"Turn left at the next intersection.\", \"This cake tastes absolutely delicious.\"],\n","    [\n","        \"I am feeling very tired after a long day.\",\n","        \"The train leaves at 5 PM. Don't be late!\",\n","    ],\n","    [\"What time does the train leave?\", \"The movie was better than I expected.\"],\n","]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-27T01:34:07.022817Z","iopub.status.busy":"2024-11-27T01:34:07.022377Z","iopub.status.idle":"2024-11-27T01:34:35.157156Z","shell.execute_reply":"2024-11-27T01:34:35.151523Z","shell.execute_reply.started":"2024-11-27T01:34:07.022785Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67e0304408e4479798c30977b7a15c0d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea02fb576f964f8888d9283e1fbb4a7c","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24545df13e714e28a2541f5a9ecfecbd","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b17766d02c5343348f836a121cfcf9ae","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32582eb1c7be419b9ae1320dc778734f","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfeb0e27a3d14be7b62e071e3bdab927","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26aeb59caedc4d1a846393aeb17597be","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f69b710d4d274a17acaffcf3b089c1af","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ba59ae46ef546bd8fe8973b7c41c261","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/3.99k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"617e3af5ffbe44d09a34989312123c6a","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c94ff05af21b48a1ba34eb52bf2e4329","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49761c4b4c21456a8a0b766e14ee0aaa","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ecc927435f442d39f3db865674f5ac8","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03f952df36674ad5b2bae9a38f2e4826","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"128b9764344c49eea0f529e353f3cc63","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e90fd7b9e04748709278b71490a1bfe0","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f6fad857f9841fcac1a9bebe2c5b9f1","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7fa99183151423cac9ab1316815a543","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Similarity Percentage =  27.964735\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","\n","# Load pre-trained summarization model\n","model_name = \"facebook/bart-large-cnn\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","# Input text\n","summary_res = []\n","for i in range(2):\n","    text = \";\".join(res_l[i])\n","\n","    # Tokenize and summarize\n","    inputs = tokenizer.encode(\n","        \"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True\n","    )\n","    summary_ids = model.generate(\n","        inputs,\n","        max_length=512,\n","        min_length=40,\n","        length_penalty=2.0,\n","        num_beams=4,\n","        early_stopping=True,\n","    )\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","    summary_res.append(summary)\n","\n","embedder_model_name = \"sentence-transformers/bert-base-nli-mean-tokens\"\n","embedder_model = SentenceTransformer(embedder_model_name)\n","\n","embeding_summary = embedder_model.encode(summary_res)\n","similarity_summary = cosine_similarity([embeding_summary[0]], embeding_summary[1:])\n","print(\"Similarity Percentage = \", similarity_summary[0][0] * 100)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading model...\n","Download complete.\n"]}],"source":["import os\n","import requests\n","\n","model_url = (\n","    \"https://drive.google.com/file/d/1FkoiDorRCVekAdzJDTOgQ7-QPhUnligW/view?usp=sharing\"\n",")\n","local_file = \"finalized_model.sav\"\n","\n","if not os.path.exists(local_file):\n","    print(\"Downloading model...\")\n","    response = requests.get(model_url)\n","    with open(local_file, \"wb\") as file:\n","        file.write(response.content)\n","    print(\"Download complete.\")\n","else:\n","    print(\"Model already exists.\")"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"ename":"EOFError","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Check the type of the model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model))\n","File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/joblib/numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n","File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n","File \u001b[0;32m/opt/miniconda3/lib/python3.12/pickle.py:1246\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m key \u001b[38;5;241m=\u001b[39m read(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[0;32m-> 1246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m   1248\u001b[0m dispatch[key[\u001b[38;5;241m0\u001b[39m]](\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mEOFError\u001b[0m: "]}],"source":["import joblib\n","\n","# Load the model\n","model = joblib.load(local_file)\n","\n","# Check the type of the model\n","print(type(model))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloaded file size: 0 bytes\n"]}],"source":["import os\n","\n","print(f\"Downloaded file size: {os.path.getsize('finalized_model.sav')} bytes\")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"ename":"EOFError","evalue":"Ran out of input","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinalized_model.sav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mEOFError\u001b[0m: Ran out of input"]}],"source":["import pickle\n","\n","with open(\"finalized_model.sav\", \"rb\") as file:\n","    model = pickle.load(file)\n","\n","print(\"Model loaded successfully!\")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model already exists.\n"]}],"source":["import os\n","import requests\n","\n","model_url = \"https://drive.google.com/file/d/1FkoiDorRCVekAdzJDTOgQ7-QPhUnligW/view?usp=sharing\"  # Replace with the correct URL\n","local_file = \"finalized_model.sav\"\n","\n","if not os.path.exists(local_file):\n","    print(\"Downloading model...\")\n","    try:\n","        response = requests.get(model_url, stream=True)\n","        response.raise_for_status()  # Ensure the request was successful\n","        with open(local_file, \"wb\") as file:\n","            for chunk in response.iter_content(chunk_size=8192):  # Stream in chunks\n","                file.write(chunk)\n","        print(\"Download complete.\")\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error downloading the file: {e}\")\n","else:\n","    print(\"Model already exists.\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/bert_sentenceclassfier/pytorch/default/1/finalized_model.sav'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/bert_sentenceclassfier/pytorch/default/1/finalized_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot Similar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimilar\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     42\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move the model to the selected device\u001b[39;00m\n","File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/bert_sentenceclassfier/pytorch/default/1/finalized_model.sav'"]}],"source":["import pickle\n","import pandas as pd\n","import torch\n","\n","from transformers import (\n","    BertTokenizer,\n","    BertForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n",")\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset\n","from transformers import BertTokenizer, BertForSequenceClassification\n","import torch.nn.functional as F\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","\n","def predict(sentence1, sentence2, model, tokenizer, device, max_length=128):\n","    # Tokenize the input\n","    inputs = tokenizer(\n","        sentence1,\n","        sentence2,\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_length,\n","        return_tensors=\"pt\",\n","    ).to(\n","        device\n","    )  # Move inputs to the same device as the model\n","\n","    # Run the model\n","    with torch.no_grad():\n","        outputs = model(\n","            input_ids=inputs[\"input_ids\"],\n","            attention_mask=inputs[\"attention_mask\"],\n","        )\n","        logits = outputs.logits\n","    # Apply softmax to get probabilities\n","    probs = F.softmax(logits, dim=1)\n","    predicted_class = torch.argmax(probs).item()\n","\n","    return predicted_class, probs\n","\n","\n","filename = \"/kaggle/input/bert_sentenceclassfier/pytorch/default/1/finalized_model.sav\"\n","labels = [\"Not Similar\", \"Similar\"]\n","\n","loaded_model = pickle.load(open(filename, \"rb\"))\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","loaded_model.to(device)  # Move the model to the selected device\n","\n","# Generate two similar sentences for testing\n","sentence1 = \"Today is a very sunny day.\"\n","sentence2 = \"I am hungry, I will get my meal.\"\n","\n","# Perform inference\n","predicted_class, probabilities = predict(\n","    sentence1, sentence2, loaded_model, tokenizer, device\n",")\n","\n","# Print results\n","print(f\"Sentence 1: {sentence1}\")\n","print(f\"Sentence 2: {sentence2}\")\n","print(f\"Predicted Class: {labels[predicted_class]}\")\n","print(f\"Class Probabilities: {probabilities}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":4}
